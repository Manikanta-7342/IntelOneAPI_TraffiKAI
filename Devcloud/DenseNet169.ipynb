{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1380 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u184510/.local/lib/python3.9/site-packages/keras/preprocessing/image.py:1137: UserWarning: Found 266 invalid image filename(s) in x_col=\"image_names\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set up the data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_labels = pd.read_csv('Emergency_Vehicles/train.csv')\n",
    "# Convert the column to strings\n",
    "train_labels['emergency_or_not'] = train_labels['emergency_or_not'].astype(str)\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_labels,\n",
    "    directory='Emergency_Vehicles/train',\n",
    "    x_col='image_names',\n",
    "    y_col='emergency_or_not',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 06:31:28.504951: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /glob/development-tools/versions/oneapi/2023.0.1/oneapi/vpl/2023.0.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/tbb/2021.8.0/env/../lib/intel64/gcc4.8:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/rkcommon/1.10.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ospray_studio/0.11.1/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ospray/2.10.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/openvkl/1.3.1/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/oidn/1.4.3/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//libfabric/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//lib/release:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mkl/2023.0.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/itac/2021.8.0/slib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ispc/1.18.1/lib/lib64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ipp/2021.7.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ippcp/2021.6.3/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ipp/2021.7.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/embree/3.13.5/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/dnnl/2023.0.0/cpu_dpcpp_gpu_dpcpp/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/gdb/intel64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/libipt/intel64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/dep/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/dal/2023.0.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib/x64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib/oclfpga/host/linux64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/compiler/lib/intel64_lin:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ccl/2021.8.0/lib/cpu_gpu_dpcpp\n",
      "2023-03-17 06:31:28.505027: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-17 06:31:28.505088: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (s001-n019): /proc/driver/nvidia/version does not exist\n",
      "2023-03-17 06:31:28.507200: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 72s 1s/step - loss: 0.2923 - accuracy: 0.8761\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 55s 1s/step - loss: 0.1718 - accuracy: 0.9318\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 55s 1s/step - loss: 0.1262 - accuracy: 0.9547\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 54s 1s/step - loss: 0.1246 - accuracy: 0.9622\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 54s 1s/step - loss: 0.1145 - accuracy: 0.9607\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 53s 1s/step - loss: 0.0980 - accuracy: 0.9711\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 54s 1s/step - loss: 0.0851 - accuracy: 0.9763\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 54s 1s/step - loss: 0.0890 - accuracy: 0.9696\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 54s 1s/step - loss: 0.0911 - accuracy: 0.9718\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 54s 1s/step - loss: 0.0723 - accuracy: 0.9785\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 66s 2s/step - loss: 0.0704 - accuracy: 0.9785\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 107s 2s/step - loss: 0.0711 - accuracy: 0.9733\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 108s 2s/step - loss: 0.0765 - accuracy: 0.9703\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 92s 2s/step - loss: 0.0710 - accuracy: 0.9800\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 108s 2s/step - loss: 0.0546 - accuracy: 0.9837\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 105s 2s/step - loss: 0.0501 - accuracy: 0.9829\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 107s 2s/step - loss: 0.0477 - accuracy: 0.9881\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 105s 2s/step - loss: 0.0520 - accuracy: 0.9815\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 104s 2s/step - loss: 0.0461 - accuracy: 0.9904\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 91s 2s/step - loss: 0.0405 - accuracy: 0.9926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc662bf5730>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-trained DenseNet-169 model and freeze the base layers\n",
    "base_model = tf.keras.applications.DenseNet169(\n",
    "    include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add new fully connected layers on top of the base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Compile the model with binary cross-entropy loss and Adam optimizer\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "#freeze Layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the test CSV file with filenames\n",
    "t_test_df = pd.read_csv(\"Emergency_Vehicles/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1380 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u184510/.local/lib/python3.9/site-packages/keras/preprocessing/image.py:1137: UserWarning: Found 266 invalid image filename(s) in x_col=\"image_names\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "/home/u184510/tmp/ipykernel_470999/1260252469.py:14: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  preds = model.predict_generator(t_test_generator, steps=None)\n"
     ]
    }
   ],
   "source": [
    "# Create a generator for the test images\n",
    "t_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "t_test_generator = t_test_datagen.flow_from_dataframe(\n",
    "    t_test_df,\n",
    "    directory=\"Emergency_Vehicles/train\",\n",
    "    x_col='image_names',\n",
    "    y_col=None,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=None,\n",
    "    shuffle=False)\n",
    "\n",
    "# Use the trained model to make predictions on the test data\n",
    "preds = model.predict_generator(t_test_generator, steps=None)\n",
    "# Remove any missing filenames from the test CSV file\n",
    "missing_filenames = set(t_test_generator.filenames) - set(t_test_df['image_names'])\n",
    "if missing_filenames:\n",
    "    print(f'Removing {len(missing_filenames)} missing filenames from the test CSV file.')\n",
    "    t_test_df = t_test_df[~t_test_df['image_names'].isin(missing_filenames)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "li = []\n",
    "for i in preds.ravel():\n",
    "    if i>0.5:\n",
    "        li.append(1)\n",
    "    else:\n",
    "        li.append(0)\n",
    "     \n",
    "# Create a DataFrame with the filenames and predictions\n",
    "df = pd.DataFrame({'image_names': t_test_generator.filenames[:len(preds)], 'emergency_or_not': li})\n",
    "\n",
    "test_inst_df=pd.merge(df, t_test_df, on='image_names', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9855072463768116"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df[\"emergency_or_not\"],test_inst_df['emergency_or_not_y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[723,  19],\n",
       "       [  1, 637]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(df[\"emergency_or_not\"],test_inst_df['emergency_or_not_y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('models/densenet.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (IntelÂ® oneAPI 2023.0)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
